{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f0a8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:26.209121Z",
     "iopub.status.busy": "2024-07-31T08:40:26.208658Z",
     "iopub.status.idle": "2024-07-31T08:40:27.301853Z",
     "shell.execute_reply": "2024-07-31T08:40:27.300575Z"
    },
    "papermill": {
     "duration": 1.10685,
     "end_time": "2024-07-31T08:40:27.304664",
     "exception": false,
     "start_time": "2024-07-31T08:40:26.197814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/list-of-countries/list-of-countries.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaded1bc",
   "metadata": {
    "papermill": {
     "duration": 0.0081,
     "end_time": "2024-07-31T08:40:27.321119",
     "exception": false,
     "start_time": "2024-07-31T08:40:27.313019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this notebook we are going to scrape data for different methods and web pages.or a more detailed documentation check the articles on medium that I wrote explaining my process in depth: <br>\n",
    "[Scraping Data From Static Website Using Beautiful Soup](https://medium.com/@ritaaggelou/scraping-data-from-static-website-using-beautiful-soup-6fb81612c0d8) <br>\n",
    "[Data Scraping in a Dynamic Web Page with Python and Selenium](https://medium.com/@ritaaggelou/data-scraping-in-a-dynamic-web-page-with-python-and-selenium-ec1ca507fc81) <br>\n",
    "[API-Based Web Scraping Using Python](https://medium.com/@ritaaggelou/api-based-web-scraping-using-python-bfab2dbcb14a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb27c8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-24T10:34:58.835244Z",
     "iopub.status.busy": "2024-01-24T10:34:58.834885Z"
    },
    "papermill": {
     "duration": 0.007473,
     "end_time": "2024-07-31T08:40:27.338798",
     "exception": false,
     "start_time": "2024-07-31T08:40:27.331325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scraping Data From Static Website Using Beautiful Soup\n",
    "\n",
    "In this notebook we are going to scrape data from worldometers.info\n",
    "For the exact page click [here](https://www.worldometers.info/population/countries-in-europe-by-population/). It would be easier for the reader to have basic knowledge for HTML structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded540cc",
   "metadata": {
    "papermill": {
     "duration": 0.008493,
     "end_time": "2024-07-31T08:40:27.355740",
     "exception": false,
     "start_time": "2024-07-31T08:40:27.347247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What are we going to do?\n",
    "\n",
    "* Make a soup element in which we are going to have all the HTML code of our page\n",
    "* Detect the table in the soup, and save it in an list named \"table\"\n",
    "* We are going to use 2 empty lists. One for the header and one for all the rows of the table.\n",
    "* We will use a for loop in order to save our data in the empty lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5cf04bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:27.373341Z",
     "iopub.status.busy": "2024-07-31T08:40:27.372719Z",
     "iopub.status.idle": "2024-07-31T08:40:28.120112Z",
     "shell.execute_reply": "2024-07-31T08:40:28.118961Z"
    },
    "papermill": {
     "duration": 0.759429,
     "end_time": "2024-07-31T08:40:28.123035",
     "exception": false,
     "start_time": "2024-07-31T08:40:27.363606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "\n",
    "soup = BeautifulSoup(requests.get(\"https://www.worldometers.info/population/countries-in-europe-by-population/\").text)\n",
    "table = soup.find(\"table\", {\"id\": \"example2\"})\n",
    "header = []\n",
    "rows = []\n",
    "for i, row in enumerate(table.find_all(\"tr\")):\n",
    "    if i == 0:\n",
    "        header = [el.text.strip() for el in row.find_all(\"th\")]\n",
    "    else:\n",
    "        rows.append([el.text.strip() for el in row.find_all(\"td\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e4f3e",
   "metadata": {
    "papermill": {
     "duration": 0.007293,
     "end_time": "2024-07-31T08:40:28.138081",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.130788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's check if our data appears right into a dataframe and then we are going to save them into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab9aeb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.162321Z",
     "iopub.status.busy": "2024-07-31T08:40:28.161565Z",
     "iopub.status.idle": "2024-07-31T08:40:28.200789Z",
     "shell.execute_reply": "2024-07-31T08:40:28.199511Z"
    },
    "papermill": {
     "duration": 0.056877,
     "end_time": "2024-07-31T08:40:28.203529",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.146652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Country (or dependency)</th>\n",
       "      <th>Population (2023)</th>\n",
       "      <th>Yearly Change</th>\n",
       "      <th>Net Change</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Migrants (net)</th>\n",
       "      <th>Fert. Rate</th>\n",
       "      <th>Med. Age</th>\n",
       "      <th>Urban Pop %</th>\n",
       "      <th>World Share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Russia</td>\n",
       "      <td>144,444,359</td>\n",
       "      <td>-0.19 %</td>\n",
       "      <td>-268,955</td>\n",
       "      <td>9</td>\n",
       "      <td>16,376,870</td>\n",
       "      <td>-136,414</td>\n",
       "      <td>1.5</td>\n",
       "      <td>39</td>\n",
       "      <td>75 %</td>\n",
       "      <td>1.80 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Germany</td>\n",
       "      <td>83,294,633</td>\n",
       "      <td>-0.09 %</td>\n",
       "      <td>-75,210</td>\n",
       "      <td>239</td>\n",
       "      <td>348,560</td>\n",
       "      <td>155,751</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45</td>\n",
       "      <td>77 %</td>\n",
       "      <td>1.04 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>67,736,802</td>\n",
       "      <td>0.34 %</td>\n",
       "      <td>227,866</td>\n",
       "      <td>280</td>\n",
       "      <td>241,930</td>\n",
       "      <td>165,790</td>\n",
       "      <td>1.6</td>\n",
       "      <td>40</td>\n",
       "      <td>85 %</td>\n",
       "      <td>0.84 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>64,756,584</td>\n",
       "      <td>0.20 %</td>\n",
       "      <td>129,956</td>\n",
       "      <td>118</td>\n",
       "      <td>547,557</td>\n",
       "      <td>67,761</td>\n",
       "      <td>1.8</td>\n",
       "      <td>42</td>\n",
       "      <td>84 %</td>\n",
       "      <td>0.80 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Italy</td>\n",
       "      <td>58,870,762</td>\n",
       "      <td>-0.28 %</td>\n",
       "      <td>-166,712</td>\n",
       "      <td>200</td>\n",
       "      <td>294,140</td>\n",
       "      <td>58,496</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48</td>\n",
       "      <td>72 %</td>\n",
       "      <td>0.73 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # Country (or dependency) Population (2023) Yearly Change Net Change  \\\n",
       "0  1                  Russia       144,444,359       -0.19 %   -268,955   \n",
       "1  2                 Germany        83,294,633       -0.09 %    -75,210   \n",
       "2  3          United Kingdom        67,736,802        0.34 %    227,866   \n",
       "3  4                  France        64,756,584        0.20 %    129,956   \n",
       "4  5                   Italy        58,870,762       -0.28 %   -166,712   \n",
       "\n",
       "  Density (P/Km²) Land Area (Km²) Migrants (net) Fert. Rate Med. Age  \\\n",
       "0               9      16,376,870       -136,414        1.5       39   \n",
       "1             239         348,560        155,751        1.5       45   \n",
       "2             280         241,930        165,790        1.6       40   \n",
       "3             118         547,557         67,761        1.8       42   \n",
       "4             200         294,140         58,496        1.3       48   \n",
       "\n",
       "  Urban Pop % World Share  \n",
       "0        75 %      1.80 %  \n",
       "1        77 %      1.04 %  \n",
       "2        85 %      0.84 %  \n",
       "3        84 %      0.80 %  \n",
       "4        72 %      0.73 %  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert our list to dataframe\n",
    "df = pd.DataFrame(rows, columns=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce88f03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.221761Z",
     "iopub.status.busy": "2024-07-31T08:40:28.221394Z",
     "iopub.status.idle": "2024-07-31T08:40:28.255941Z",
     "shell.execute_reply": "2024-07-31T08:40:28.254655Z"
    },
    "papermill": {
     "duration": 0.04637,
     "end_time": "2024-07-31T08:40:28.258329",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.211959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47 entries, 0 to 46\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   #                        47 non-null     object\n",
      " 1   Country (or dependency)  47 non-null     object\n",
      " 2   Population (2023)        47 non-null     object\n",
      " 3   Yearly Change            47 non-null     object\n",
      " 4   Net Change               47 non-null     object\n",
      " 5   Density (P/Km²)          47 non-null     object\n",
      " 6   Land Area (Km²)          47 non-null     object\n",
      " 7   Migrants (net)           47 non-null     object\n",
      " 8   Fert. Rate               47 non-null     object\n",
      " 9   Med. Age                 47 non-null     object\n",
      " 10  Urban Pop %              47 non-null     object\n",
      " 11  World Share              47 non-null     object\n",
      "dtypes: object(12)\n",
      "memory usage: 4.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b345dc60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.279217Z",
     "iopub.status.busy": "2024-07-31T08:40:28.278787Z",
     "iopub.status.idle": "2024-07-31T08:40:28.289302Z",
     "shell.execute_reply": "2024-07-31T08:40:28.288091Z"
    },
    "papermill": {
     "duration": 0.023148,
     "end_time": "2024-07-31T08:40:28.291830",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.268682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save dataframe to csv file\n",
    "df.to_csv(\"population_in_Europe.csv\", header=header, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e19c6e",
   "metadata": {
    "papermill": {
     "duration": 0.007737,
     "end_time": "2024-07-31T08:40:28.307759",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.300022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Scraping in a Dynamic Web Page with Selenium\n",
    "\n",
    "The library that we are going to use to scrape our page is Selenium. Selenium is a Python Library which can automate loading and rendering websites in a browser like Chrome or Firefox.\n",
    "\n",
    "**Tip: Before you start using the code below, keep in mind that you should run it locally (I used Jupyter Notebook from Anaconda). That's why I am going to write it here as comments and not as a code.**\n",
    "\n",
    "In our first attempt we are going to get the entire website content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4501b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.327853Z",
     "iopub.status.busy": "2024-07-31T08:40:28.327430Z",
     "iopub.status.idle": "2024-07-31T08:40:28.332760Z",
     "shell.execute_reply": "2024-07-31T08:40:28.331660Z"
    },
    "papermill": {
     "duration": 0.017646,
     "end_time": "2024-07-31T08:40:28.335101",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.317455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "# %pip install selenium\n",
    "# %pip install webdriver-manager\n",
    "\n",
    "# from selenium import webdriver \n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "# from webdriver_manager.chrome import ChromeDriverManager \n",
    " \n",
    "# load website\n",
    "# url = 'https://angular.dev' \n",
    "\n",
    "# instantiate driver \n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install())) \n",
    "# get the entire website content\n",
    "# driver.get(url) \n",
    " \n",
    "# print(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78231d9e",
   "metadata": {
    "papermill": {
     "duration": 0.007842,
     "end_time": "2024-07-31T08:40:28.351036",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.343194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let’s attempt something different. We are going to save into a directory all the links the webpage has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b650c0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.368507Z",
     "iopub.status.busy": "2024-07-31T08:40:28.368137Z",
     "iopub.status.idle": "2024-07-31T08:40:28.373702Z",
     "shell.execute_reply": "2024-07-31T08:40:28.372523Z"
    },
    "papermill": {
     "duration": 0.017213,
     "end_time": "2024-07-31T08:40:28.376158",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.358945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from selenium import webdriver \n",
    "# from selenium.webdriver.common.by import By \n",
    "# from selenium.webdriver.chrome.service import Service as ChromeService \n",
    "# from webdriver_manager.chrome import ChromeDriverManager \n",
    " \n",
    "# instantiate options \n",
    "# options = webdriver.ChromeOptions() \n",
    " \n",
    "# run browser in headless mode \n",
    "# options.headless = True \n",
    " \n",
    "# instantiate driver \n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options) \n",
    " \n",
    "# load website \n",
    "# url = 'https://angular.dev' \n",
    " \n",
    "# get the entire website content \n",
    "# driver.get(url) \n",
    "# create an empty dictionary\n",
    "# link={}\n",
    "\n",
    "# create a parameter for the dictionary\n",
    "# j=0\n",
    "\n",
    "# select elements by tag name \n",
    "# a_elements = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "# for i in a_elements: \n",
    " # select link, within element\n",
    " # link[j] = i.get_attribute(\"href\")\n",
    " # print links \n",
    " # print(link[j])\n",
    " # j = j + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e60cb5",
   "metadata": {
    "papermill": {
     "duration": 0.007733,
     "end_time": "2024-07-31T08:40:28.391963",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.384230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Scrapping Using API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a861c1e",
   "metadata": {
    "papermill": {
     "duration": 0.007662,
     "end_time": "2024-07-31T08:40:28.407439",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.399777",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this example we will gather some data about different countries from wikipedia, as it has many relevant informations. We will use the MediaWiki API to scrape those data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c8d91c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:40:28.425877Z",
     "iopub.status.busy": "2024-07-31T08:40:28.424976Z",
     "iopub.status.idle": "2024-07-31T08:41:25.675710Z",
     "shell.execute_reply": "2024-07-31T08:41:25.673675Z"
    },
    "papermill": {
     "duration": 57.263392,
     "end_time": "2024-07-31T08:41:25.678789",
     "exception": false,
     "start_time": "2024-07-31T08:40:28.415397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wptools\r\n",
      "  Obtaining dependency information for wptools from https://files.pythonhosted.org/packages/e2/5c/0d8af5532e44477edeb3dac81d3a611ea75827a18b6b4068c3cc2188bfe5/wptools-0.4.17-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading wptools-0.4.17-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from wptools) (2023.11.17)\r\n",
      "Collecting html2text (from wptools)\r\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from wptools) (5.1.0)\r\n",
      "Collecting pycurl (from wptools)\r\n",
      "  Obtaining dependency information for pycurl from https://files.pythonhosted.org/packages/64/d2/a4c45953aed86f5a0c9717421dd725ec61acecd63777dd71dfe3d50d3e16/pycurl-7.45.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\r\n",
      "  Downloading pycurl-7.45.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\r\n",
      "Downloading wptools-0.4.17-py2.py3-none-any.whl (38 kB)\r\n",
      "Downloading pycurl-7.45.3-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: html2text\r\n",
      "  Building wheel for html2text (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33110 sha256=979686ed894e18991aba22f48829e6126906dd64d0487f74b7359e341764dfbe\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\r\n",
      "Successfully built html2text\r\n",
      "Installing collected packages: pycurl, html2text, wptools\r\n",
      "Successfully installed html2text-2024.2.26 pycurl-7.45.3 wptools-0.4.17\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting wikipedia\r\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (4.12.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wikipedia) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.11.17)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\r\n",
      "Building wheels for collected packages: wikipedia\r\n",
      "  Building wheel for wikipedia (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=06a5a049cbe138ac82b5811ed86530c0e0f4df31bd8c62ff90b463841ce1c14f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\r\n",
      "Successfully built wikipedia\r\n",
      "Installing collected packages: wikipedia\r\n",
      "Successfully installed wikipedia-1.4.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.10/site-packages (1.9.2)\r\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.10/site-packages (from wordcloud) (1.24.3)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from wordcloud) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from wordcloud) (3.7.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (4.42.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->wordcloud) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chardet\r\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: chardet\r\n",
      "Successfully installed chardet-5.2.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required tools\n",
    "%pip install wptools\n",
    "%pip install wikipedia\n",
    "%pip install wordcloud\n",
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c67f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:25.702960Z",
     "iopub.status.busy": "2024-07-31T08:41:25.702465Z",
     "iopub.status.idle": "2024-07-31T08:41:25.770503Z",
     "shell.execute_reply": "2024-07-31T08:41:25.769161Z"
    },
    "papermill": {
     "duration": 0.083807,
     "end_time": "2024-07-31T08:41:25.773277",
     "exception": false,
     "start_time": "2024-07-31T08:41:25.689470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wptools version : 0.4.17\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "\n",
    "import json\n",
    "import wptools\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "# checking the installed version\n",
    "print('wptools version : {}'.format(wptools.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35919a0b",
   "metadata": {
    "papermill": {
     "duration": 0.010075,
     "end_time": "2024-07-31T08:41:25.794195",
     "exception": false,
     "start_time": "2024-07-31T08:41:25.784120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am going to use a list with all the countries names. I found it [here](http://goodcsv.com/geography/countries/). You can easily find datasets like this in many repositories freely. I then upload it in my notebook but I couldn't read it with pandas. Perhaps the coding was different. So, I use chardet library in order to read this csv file.\n",
    "\n",
    "The chardet library reads the file in binary mode and tries to detect the encoding format based on the byte sequence in the file. Once it detects the encoding format, it passes it to the encoding parameter in the pd.read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83e1c8b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:25.817084Z",
     "iopub.status.busy": "2024-07-31T08:41:25.816626Z",
     "iopub.status.idle": "2024-07-31T08:41:25.943302Z",
     "shell.execute_reply": "2024-07-31T08:41:25.942210Z"
    },
    "papermill": {
     "duration": 0.141255,
     "end_time": "2024-07-31T08:41:25.945899",
     "exception": false,
     "start_time": "2024-07-31T08:41:25.804644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Formal Name (if different)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Islamic Republic of Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Republic of Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>People's Democratic Republic of Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Principality of Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Republic of Angola</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Common Name                Formal Name (if different)\n",
       "0  Afghanistan          Islamic Republic of Afghanistan \n",
       "1      Albania                      Republic of Albania \n",
       "2      Algeria  People's Democratic Republic of Algeria \n",
       "3      Andorra                  Principality of Andorra \n",
       "4       Angola                       Republic of Angola "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "with open('/kaggle/input/list-of-countries/list-of-countries.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    \n",
    "df = pd.read_csv('/kaggle/input/list-of-countries/list-of-countries.csv', encoding=result['encoding'])            \n",
    "df.head()                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d9bdd",
   "metadata": {
    "papermill": {
     "duration": 0.010486,
     "end_time": "2024-07-31T08:41:25.967330",
     "exception": false,
     "start_time": "2024-07-31T08:41:25.956844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This list is only for learning purposes so, I am going to use only the first 10 countries from my list. But go ahead and use it all if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1179b8d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:25.990454Z",
     "iopub.status.busy": "2024-07-31T08:41:25.990011Z",
     "iopub.status.idle": "2024-07-31T08:41:25.996247Z",
     "shell.execute_reply": "2024-07-31T08:41:25.995200Z"
    },
    "papermill": {
     "duration": 0.020666,
     "end_time": "2024-07-31T08:41:25.998740",
     "exception": false,
     "start_time": "2024-07-31T08:41:25.978074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# no of countries we are interested\n",
    "No_countries = 10 \n",
    "\n",
    "# only selecting the first 10 countries of the list                        \n",
    "df_10 = df.iloc[:No_countries, :].copy()\n",
    "# converting the column to a list \n",
    "countries = df_10['Common Name'].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd4e46a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:26.022622Z",
     "iopub.status.busy": "2024-07-31T08:41:26.022180Z",
     "iopub.status.idle": "2024-07-31T08:41:26.028510Z",
     "shell.execute_reply": "2024-07-31T08:41:26.027240Z"
    },
    "papermill": {
     "duration": 0.021808,
     "end_time": "2024-07-31T08:41:26.031576",
     "exception": false,
     "start_time": "2024-07-31T08:41:26.009768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Afghanistan\n",
      "2. Albania\n",
      "3. Algeria\n",
      "4. Andorra\n",
      "5. Angola\n",
      "6. Antigua and Barbuda \n",
      "7. Argentina\n",
      "8. Armenia\n",
      "9. Australia\n",
      "10. Austria\n"
     ]
    }
   ],
   "source": [
    "# looping through the list of 10 countries\n",
    "for i, j in enumerate(countries):   \n",
    "    print('{}. {}'.format(i+1, j)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea625204",
   "metadata": {
    "papermill": {
     "duration": 0.010438,
     "end_time": "2024-07-31T08:41:26.052983",
     "exception": false,
     "start_time": "2024-07-31T08:41:26.042545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One issue with matching the 10 countries from our list to their wikipedia article names is that both of them would not be exactly the same i.e. they match character for character. There will be slight variation in their names.\n",
    "\n",
    "To overcome this problem and ensure that we have all the countries names and its corresponding wikipedia article, we will use the wikipedia package to get suggestions for the countries names and their equivalent in wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf4afcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:26.075983Z",
     "iopub.status.busy": "2024-07-31T08:41:26.075548Z",
     "iopub.status.idle": "2024-07-31T08:41:29.677709Z",
     "shell.execute_reply": "2024-07-31T08:41:29.675981Z"
    },
    "papermill": {
     "duration": 3.617464,
     "end_time": "2024-07-31T08:41:29.681129",
     "exception": false,
     "start_time": "2024-07-31T08:41:26.063665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Afghanistan :\n",
      "Afghanistan, War in Afghanistan (2001–2021), Soviet–Afghan War, Afghan, Afghans, Provinces of Afghanistan, History of Afghanistan, President of Afghanistan, Taliban, Withdrawal of United States troops from Afghanistan\n",
      "\n",
      "\n",
      "2. Albania :\n",
      "Albania, Albanians, Albania national football team, History of Albania, People's Socialist Republic of Albania, Albanian language, Demographics of Albania, Counties of Albania, Italian protectorate of Albania (1939–1943), List of heads of state of Albania\n",
      "\n",
      "\n",
      "3. Algeria :\n",
      "Algeria, Algerian War, French Algeria, Algeria national football team, Communes of Algeria, Algerians, Algerian, List of cities in Algeria, List of universities in Algeria, Foreign relations of Algeria\n",
      "\n",
      "\n",
      "4. Andorra :\n",
      "Andorra, Co-princes of Andorra, Andorra la Vella, Andorran, FC Andorra, Andorra at the Olympics, Andorra national football team, History of Andorra, Andorra (disambiguation), Demographics of Andorra\n",
      "\n",
      "\n",
      "5. Angola :\n",
      "Angola, Angolan, Louisiana State Penitentiary, Flag of Angola, Angolan Civil War, MPLA, Angola at the Olympics, President of Angola, White Angolans, Provinces of Angola\n",
      "\n",
      "\n",
      "6. Antigua and Barbuda  :\n",
      "Antigua and Barbuda, Barbuda, Antigua, St. John's, Antigua and Barbuda, History of Antigua and Barbuda, Antigua and Barbuda national football team, Flag of Antigua and Barbuda, Monarchy of Antigua and Barbuda, Antigua and Barbuda at the Olympics, Governor-General of Antigua and Barbuda\n",
      "\n",
      "\n",
      "7. Argentina :\n",
      "Argentina, Argentina national football team, Argentines, Argentina national under-23 football team, List of Argentine provinces by Human Development Index, Buenos Aires, Argentina at the Olympics, Greater argentine, Argentina men's national handball team, Argentine Primera División\n",
      "\n",
      "\n",
      "8. Armenia :\n",
      "Armenia, Armenians, Armenian Apostolic Church, Armenian language, Armenian, Armenian genocide, Kingdom of Armenia (antiquity), History of Armenia, Armenia at the Olympics, Nagorno-Karabakh conflict\n",
      "\n",
      "\n",
      "9. Australia :\n",
      "Australia, Order of Australia, Western Australia, Indigenous Australians, List of the busiest airports in Australia, History of Australia, Australia at the Olympics, Paramount Networks UK & Australia, Aboriginal Australians, Chapter I of the Constitution of Australia\n",
      "\n",
      "\n",
      "10. Austria :\n",
      "Austria, Austria-Hungary, Austrian Empire, Austrians, Fugging, List of cities and towns in Austria, Habsburg monarchy, History of Austria, List of Austrian flags, Anschluss\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# searching for suggestions in wikipedia\n",
    "wiki_search = [{country : wikipedia.search(country)} for country in countries]\n",
    "\n",
    "for idx, country in enumerate(wiki_search):\n",
    "    for i, j in country.items():\n",
    "        print('{}. {} :\\n{}'.format(idx+1, i ,', '.join(j)))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707cd9a",
   "metadata": {
    "papermill": {
     "duration": 0.011697,
     "end_time": "2024-07-31T08:41:29.808508",
     "exception": false,
     "start_time": "2024-07-31T08:41:29.796811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's get the most probable ones (the first suggestion) for each of the first 10 countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6d8f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:29.835083Z",
     "iopub.status.busy": "2024-07-31T08:41:29.834641Z",
     "iopub.status.idle": "2024-07-31T08:41:29.842176Z",
     "shell.execute_reply": "2024-07-31T08:41:29.840870Z"
    },
    "papermill": {
     "duration": 0.024003,
     "end_time": "2024-07-31T08:41:29.844615",
     "exception": false,
     "start_time": "2024-07-31T08:41:29.820612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Probable: \n",
      " [('Afghanistan', 'Afghanistan'), ('Albania', 'Albania'), ('Algeria', 'Algeria'), ('Andorra', 'Andorra'), ('Angola', 'Angola'), ('Antigua and Barbuda ', 'Antigua and Barbuda'), ('Argentina', 'Argentina'), ('Armenia', 'Armenia'), ('Australia', 'Australia'), ('Austria', 'Austria')] \n",
      "\n",
      "Final List: \n",
      " ['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Australia', 'Austria']\n"
     ]
    }
   ],
   "source": [
    "most_probable = [(country, wiki_search[i][country][0]) for i, country in enumerate(countries)]\n",
    "countries = [x[1] for x in most_probable]\n",
    "\n",
    "print('Most Probable: \\n', most_probable,'\\n')\n",
    "\n",
    "# print final list\n",
    "print('Final List: \\n', countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cc7a2",
   "metadata": {
    "papermill": {
     "duration": 0.011057,
     "end_time": "2024-07-31T08:41:29.867459",
     "exception": false,
     "start_time": "2024-07-31T08:41:29.856402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have the names of the countries to their corresponding wikipedia article let's retrieve the infobox data from those pages.\n",
    "\n",
    "wptools provides easy to use methods to directly call the MediaWiki API on our behalf and get us all the wikipedia data. Let's try retrieving data for Afghanistan, the first name of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6c5acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:29.892356Z",
     "iopub.status.busy": "2024-07-31T08:41:29.891862Z",
     "iopub.status.idle": "2024-07-31T08:41:30.837020Z",
     "shell.execute_reply": "2024-07-31T08:41:30.834906Z"
    },
    "papermill": {
     "duration": 0.9621,
     "end_time": "2024-07-31T08:41:30.840995",
     "exception": false,
     "start_time": "2024-07-31T08:41:29.878895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en.wikipedia.org (parse) Afghanistan\n",
      "Afghanistan (en) data\n",
      "{\n",
      "  infobox: <dict(86)> conventional_long_name, common_name, native_...\n",
      "  iwlinks: <list(11)> https://commons.wikimedia.org/wiki/%D8%A7%D9...\n",
      "  pageid: 737\n",
      "  parsetree: <str(402668)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Afghanistan\n",
      "  wikibase: Q889\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q889\n",
      "  wikitext: <str(325648)> {{short description|Country in South-Cen...\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['requests', 'iwlinks', 'pageid', 'wikitext', 'parsetree', 'infobox', 'title', 'wikibase', 'wikidata_url'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parses the wikipedia article\n",
    "page = wptools.page('Afghanistan')\n",
    "page.get_parse()   \n",
    "page.data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8561908f",
   "metadata": {
    "papermill": {
     "duration": 0.011359,
     "end_time": "2024-07-31T08:41:30.864662",
     "exception": false,
     "start_time": "2024-07-31T08:41:30.853303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see from the output above, wptools successfully retrieved the wikipedia and wikidata corresponding to the query Afghanistan. We only want data from the infobox. Let's retrieve them and see what we are going to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45609c19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:30.889639Z",
     "iopub.status.busy": "2024-07-31T08:41:30.888654Z",
     "iopub.status.idle": "2024-07-31T08:41:30.898502Z",
     "shell.execute_reply": "2024-07-31T08:41:30.897364Z"
    },
    "papermill": {
     "duration": 0.025199,
     "end_time": "2024-07-31T08:41:30.901147",
     "exception": false,
     "start_time": "2024-07-31T08:41:30.875948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conventional_long_name': 'Islamic Emirate of Afghanistan',\n",
       " 'common_name': 'Afghanistan',\n",
       " 'native_name': '{{unbulleted list|native name|ps|د افغانستان اسلامي امارت|italic|=|no|<br />|small|transliteration|ps|Də Afġānistān Islāmī Imārat|native name|prs|امارت اسلامی افغانستان|italic|=|no|<br />|small|transliteration|prs|Imārat-i Islāmī-yi Afğānistān}} {{native name|ps|د افغانستان اسلامي امارت|italic|=|no}} <br /> {{small|transliteration|ps|Də Afġānistān Islāmī Imārat}} {{transliteration|ps|Də Afġānistān Islāmī Imārat}} {{native name|prs|امارت اسلامی افغانستان|italic|=|no}} <br /> {{small|transliteration|prs|Imārat-i Islāmī-yi Afğānistān}} {{transliteration|prs|Imārat-i Islāmī-yi Afğānistān}}',\n",
       " 'image_flag': 'Flag of Taliban.svg',\n",
       " 'flag_caption': 'Flag',\n",
       " 'image_coat': 'Arms of the Islamic Emirate of Afghanistan.svg',\n",
       " 'alt_coat': 'Coat of Arms of the Islamic Emirate',\n",
       " 'symbol_type': '[[Emblem of Afghanistan|Emblem]]',\n",
       " 'national_motto': '{{lang|ar|لا إله إلا الله، محمد رسول الله}} <br/> {{transliteration|ar|Lā ʾilāha ʾillā llāh, Muhammadun rasūlu llāh}} <br/>\\n\"There is no god but [[God in Islam|God]]; [[Muhammad]] is the messenger of God.\" (\\'\\'[[Shahadah]]\\'\\')',\n",
       " 'national_anthem': '{{lang|ps|دا د باتورانو کور}} <br />\" {{transliteration|ps|Dā Də Bātorāno Kor}} \"<br />\"[[This Is the Home of the Brave]]\" <br>',\n",
       " 'image_map': \"{{switcher|[[File:Afghanistan (orthographic projection).svg|upright=1.15|frameless]]|Afghanistan on the globe|[[File:Afghanistan - Location Map (2013) - AFG - UNOCHA.svg|upright=1.15|frameless]]|Afghanistan's neighbors and towns}}\",\n",
       " 'capital': '[[Kabul]]',\n",
       " 'coordinates': '{{Coord|34|31|N|69|11|E|region:AF_source:geonames|display|=|inline,title}}',\n",
       " 'largest_city': 'Kabul',\n",
       " 'official_languages': '{{hlist|[[Pashto]]|[[Dari]]}}',\n",
       " 'ethnic_groups': '{{unbulleted list\\n | 42% [[Pashtun]]\\n | 27% [[Tajiks|Tajik]]\\n | |figure space|9% [[Hazaras|Hazara]]\\n | |figure space|9% [[Uzbeks|Uzbek]]\\n | |figure space|4% [[Aimaq people|Aimaq]]\\n | |figure space|3% [[Turkmen people|Turkmen]]\\n | |figure space|2% [[Baloch people|Baloch]]\\n | |figure space|4% [[Ethnic groups in Afghanistan|other]]}} {{figure space}} 9% [[Hazaras|Hazara]] {{figure space}} 9% [[Uzbeks|Uzbek]] {{figure space}} 4% [[Aimaq people|Aimaq]] {{figure space}} 3% [[Turkmen people|Turkmen]] {{figure space}} 2% [[Baloch people|Baloch]] {{figure space}} 4% [[Ethnic groups in Afghanistan|other]]',\n",
       " 'ethnic_groups_ref': '{{efn|The last census in Afghanistan was conducted in 1979, and was itself incomplete. Due to the [[Afghan conflict|ongoing conflict]] in the country, no official census has been conducted since.|ref| name=\"Population Matters\"}}',\n",
       " 'ethnic_groups_year': '2019 unofficial estimates',\n",
       " 'religion': '{{unbulleted list\\n | 99.7% [[Islam in Afghanistan|Islam]] ([[State religion|official]])\\n | 0.3% [[Demographics of Afghanistan#Religion|other]]}}',\n",
       " 'religion_year': '2015',\n",
       " 'demonym': '[[Afghans|Afghan]] {{Efn|Other demonyms that have been used are Afghani,|ref|Dictionary.com. [[The American Heritage Dictionary of the English Language]], Fourth Edition. Houghton Mifflin Company, 2004. [http://dictionary.reference.com/browse/afghani Reference.com] {{Webarchive|url=https://web.archive.org/web/20160303185738/http://dictionary.reference.com/browse/afghani |date=3 March 2016 }} (Retrieved 13 November 2007).|</ref>| Afghanese and Afghanistani (see [[Afghans]] for further details)|ref|Dictionary.com. [[WordNet]] 3.0. [[Princeton University]]. [http://dictionary.reference.com/browse/afghanistani Reference.com] (Retrieved 13 November 2007). {{webarchive |url=https://web.archive.org/web/20140328102257/http://dictionary.reference.com/browse/afghanistani |date=28 March 2014}}|</ref>|name|=|\"Demonym\"|group|=|\"Note\"}} Afghanese and Afghanistani (see [[Afghans]] for further details)',\n",
       " 'government_type': 'Unitary [[totalitarian]] provisional [[theocratic]] Islamic [[emirate]]',\n",
       " 'leader_title1': '[[Supreme Leader of Afghanistan|Supreme leader]]',\n",
       " 'leader_name1': '{{nowrap|[[Hibatullah Akhundzada]]}}',\n",
       " 'leader_title2': '[[Prime Minister of Afghanistan|Prime minister]]',\n",
       " 'leader_name2': '[[Hasan Akhund]] ([[Acting prime minister|acting]])',\n",
       " 'leader_title3': '[[Chief Justice of Afghanistan|Chief justice]]',\n",
       " 'leader_name3': '[[Abdul Hakim Haqqani]]',\n",
       " 'legislature': \"None {{efn|Afghanistan is a pure [[autocracy]], with all law ultimately originating from the supreme leader. Consensus rule was initially used among the Taliban, but was phased out as the supreme leader monopolized control in the months following the 2021 return to power.|ref|{{cite web |author1=T. S. Tirumurti |title=Letter dated 25 May 2022 from the Chair of the Security Council Committee established pursuant to resolution 1988 (2011) addressed to the President of the Security Council |url=https://digitallibrary.un.org/record/3975071/files/S_2022_419-EN.pdf?ln=en |publisher=[[United Nations Security Council]] |access-date=2 May 2023 |date=26 May 2022}}|</ref>|ref|{{cite news |last1=Kraemer |first1=Thomas |title=Afghanistan dispatch: Taliban leaders issue new orders on law-making process, enforcement of court orders from previous government |url=https://www.jurist.org/news/2022/11/afghanistan-dispatch-taliban-leaders-issue-new-orders-on-law-making-process-enforcement-of-court-orders-from-previous-government/ |access-date=1 May 2023 |work=[[JURIST]] |date=27 November 2022 |archive-date=17 January 2024 |archive-url=https://web.archive.org/web/20240117233605/https://www.jurist.org/news/2022/11/afghanistan-dispatch-taliban-leaders-issue-new-orders-on-law-making-process-enforcement-of-court-orders-from-previous-government/ |url-status=live }}|</ref>|ref|{{cite news |last1=Dawi |first1=Akmal |title=Unseen Taliban Leader Wields Godlike Powers in Afghanistan |url=https://www.voanews.com/a/unseen-taliban-leader-wields-godlike-powers-in-afghanistan-/7026112.html |access-date=1 May 2023 |publisher=[[Voice of America]] |date=28 March 2023 |archive-date=13 April 2023 |archive-url=https://web.archive.org/web/20230413041049/https://www.voanews.com/a/unseen-taliban-leader-wields-godlike-powers-in-afghanistan-/7026112.html |url-status=live }}|</ref>| There is an advisory [[Leadership Council of Afghanistan|Leadership Council]], however its role is in question as the supreme leader has not convened it for many months (|as of|lc|=|y|2023|03|post|=|),| and increasingly rules by decree.|ref|{{cite journal |author1=Oxford Analytica |author1-link=Oxford Analytica |title=Senior Afghan Taliban figures move to curb leader |journal=Expert Briefings |series=Emerald Expert Briefings |date=10 March 2023 |doi=10.1108/OXAN-DB276639 |quote=[Akhundzada] has not convened the Taliban's Leadership Council (a 'politburo' of top leaders and commanders) for several months. Instead, he relies on the narrower Kandahar Council of Clerics for legal advice.}}|</ref>}} There is an advisory [[Leadership Council of Afghanistan|Leadership Council]], however its role is in question as the supreme leader has not convened it for many months ( {{as of|lc|=|y|2023|03|post|=|),}} and increasingly rules by decree.\",\n",
       " 'sovereignty_type': '[[History of Afghanistan|Formation]]',\n",
       " 'established_event1': '[[Hotak dynasty]]',\n",
       " 'established_date1': '[[Mirwais Hotak|1709]]–[[Siege of Kandahar|1738]]',\n",
       " 'established_event2': '{{nowrap|[[Durrani Empire]]}}',\n",
       " 'established_date2': '1747–1823',\n",
       " 'established_event3': '[[Emirate of Afghanistan|Emirate]]',\n",
       " 'established_date3': '1823–1839',\n",
       " 'established_event4': '[[Durrani Empire|Restoration of the Durrani Kingdom]]',\n",
       " 'established_date4': '[[First Anglo-Afghan War|1839–1842]]',\n",
       " 'established_event5': '[[Emirate of Afghanistan|Restoration of the Emirate]]',\n",
       " 'established_date5': '[[First Anglo-Afghan War|1842–1926]]',\n",
       " 'established_event6': '[[Dost Mohammad Khan|Dost Mohammad unites Afghanistan]]',\n",
       " 'established_date6': '[[Herat Campaign of 1862–63|27 May 1863]]',\n",
       " 'established_event7': '[[Treaty of Gandamak|Anglo-Afghan Agreement]]',\n",
       " 'established_date7': '[[Second Anglo-Afghan War|26 May 1879]]',\n",
       " 'established_event8': '[[Third Anglo-Afghan War|Independence]]',\n",
       " 'established_date8': '[[Afghan Independence Day|19 August 1919]]',\n",
       " 'established_event9': '[[Kingdom of Afghanistan|Kingdom]]',\n",
       " 'established_date9': '9 June 1926',\n",
       " 'established_event10': '[[Republic of Afghanistan (1973–1978)|Republic]]',\n",
       " 'established_date10': \"[[1973 Afghan coup d'état|17 July 1973]]\",\n",
       " 'established_event11': '[[Democratic Republic of Afghanistan|Democratic Republic]]',\n",
       " 'established_date11': '[[Saur Revolution|27–28 April 1978]]',\n",
       " 'established_event12': '[[Islamic State of Afghanistan|Islamic State]]',\n",
       " 'established_date12': '28 April 1992',\n",
       " 'established_event13': '[[Islamic Emirate of Afghanistan (1996–2001)|Islamic Emirate]]',\n",
       " 'established_date13': '27 September 1996',\n",
       " 'established_event14': '{{nowrap|[[Islamic Republic of Afghanistan|Islamic Republic]]}}',\n",
       " 'established_date14': '26 January 2004',\n",
       " 'established_event15': '[[Fall of Kabul (2021)|Restoration of Islamic Emirate]]',\n",
       " 'established_date15': '15 August 2021',\n",
       " 'area_km2': '652,867',\n",
       " 'area_rank': '40th',\n",
       " 'area_sq_mi': '252,072',\n",
       " 'percent_water': 'negligible',\n",
       " 'population_estimate': '{{IncreaseNeutral}} 41,128,771',\n",
       " 'population_estimate_year': '2023',\n",
       " 'population_estimate_rank': '37th',\n",
       " 'population_density_km2': '48.08',\n",
       " 'population_density_sq_mi': '119',\n",
       " 'GDP_PPP': '$81.007&nbsp;billion',\n",
       " 'GDP_PPP_year': '2020',\n",
       " 'GDP_PPP_per_capita': '$2,459',\n",
       " 'GDP_nominal': '$20.136&nbsp;billion',\n",
       " 'GDP_nominal_year': '2020',\n",
       " 'GDP_nominal_per_capita': '$611',\n",
       " 'HDI': '0.462',\n",
       " 'HDI_year': '2022',\n",
       " 'HDI_change': 'decrease',\n",
       " 'HDI_rank': '182nd',\n",
       " 'currency': '[[Afghan afghani|Afghani]] ( {{lang|prs|افغانى}} )',\n",
       " 'currency_code': 'AFN',\n",
       " 'time_zone': '[[Afghanistan Time]]',\n",
       " 'utc_offset': '+4:30<br />[[Lunar Hijri calendar|Lunar Calendar]]',\n",
       " 'DST_note': \"''[[Daylight saving time|DST]] is not observed''\",\n",
       " 'cctld': '[[.af]]',\n",
       " 'status': '[[UN member state]] under an [[Recognition of the Islamic Emirate of Afghanistan|unrecognized government]]'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.data['infobox']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c99c59d",
   "metadata": {
    "papermill": {
     "duration": 0.011518,
     "end_time": "2024-07-31T08:41:30.924757",
     "exception": false,
     "start_time": "2024-07-31T08:41:30.913239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will define a list of features that we want from the infoboxes as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aeac8e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:30.949778Z",
     "iopub.status.busy": "2024-07-31T08:41:30.949411Z",
     "iopub.status.idle": "2024-07-31T08:41:39.187762Z",
     "shell.execute_reply": "2024-07-31T08:41:39.186046Z"
    },
    "papermill": {
     "duration": 8.254336,
     "end_time": "2024-07-31T08:41:39.190692",
     "exception": false,
     "start_time": "2024-07-31T08:41:30.936356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "en.wikipedia.org (parse) Afghanistan\n",
      "Afghanistan (en) data\n",
      "{\n",
      "  infobox: <dict(86)> conventional_long_name, common_name, native_...\n",
      "  iwlinks: <list(11)> https://commons.wikimedia.org/wiki/%D8%A7%D9...\n",
      "  pageid: 737\n",
      "  parsetree: <str(402668)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Afghanistan\n",
      "  wikibase: Q889\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q889\n",
      "  wikitext: <str(325648)> {{short description|Country in South-Cen...\n",
      "}\n",
      "en.wikipedia.org (parse) Albania\n",
      "Albania (en) data\n",
      "{\n",
      "  infobox: <dict(89)> conventional_long_name, native_name, common_...\n",
      "  iwlinks: <list(25)> https://commons.wikimedia.org/wiki/Atlas_of_...\n",
      "  pageid: 738\n",
      "  parsetree: <str(346725)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Albania\n",
      "  wikibase: Q222\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q222\n",
      "  wikitext: <str(276325)> {{short description|Country in Southeast...\n",
      "}\n",
      "en.wikipedia.org (parse) Algeria\n",
      "Algeria (en) data\n",
      "{\n",
      "  infobox: <dict(77)> conventional_long_name, native_name, common_...\n",
      "  iwlinks: <list(11)> https://commons.wikimedia.org/wiki/%D8%A7%D9...\n",
      "  pageid: 358\n",
      "  parsetree: <str(253559)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Algeria\n",
      "  wikibase: Q262\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q262\n",
      "  wikitext: <str(204011)> {{short description|Country in North Afr...\n",
      "}\n",
      "en.wikipedia.org (parse) Andorra\n",
      "Andorra (en) data\n",
      "{\n",
      "  infobox: <dict(74)> conventional_long_name, common_name, native_...\n",
      "  iwlinks: <list(16)> https://ca.wikipedia.org/wiki/Castellers_d%2...\n",
      "  pageid: 600\n",
      "  parsetree: <str(194627)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Andorra\n",
      "  wikibase: Q228\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q228\n",
      "  wikitext: <str(136222)> {{short description|Country in Western E...\n",
      "}\n",
      "en.wikipedia.org (parse) Angola\n",
      "Angola (en) data\n",
      "{\n",
      "  infobox: <dict(67)> conventional_long_name, common_name, native_...\n",
      "  iwlinks: <list(14)> https://commons.wikimedia.org/wiki/Angola, h...\n",
      "  pageid: 701\n",
      "  parsetree: <str(213299)> <root><template><title>Short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Angola\n",
      "  wikibase: Q916\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q916\n",
      "  wikitext: <str(170009)> {{Short description|Country on the west ...\n",
      "}\n",
      "en.wikipedia.org (parse) Antigua and Barbuda\n",
      "Antigua and Barbuda (en) data\n",
      "{\n",
      "  infobox: <dict(77)> conventional_long_name, languages_type, lang...\n",
      "  iwlinks: <list(11)> https://commons.wikimedia.org/wiki/Antigua_a...\n",
      "  pageid: 951\n",
      "  parsetree: <str(108636)> <root><template><title>Short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Antigua and Barbuda\n",
      "  wikibase: Q781\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q781\n",
      "  wikitext: <str(81270)> {{Short description|Country in the Lesser...\n",
      "}\n",
      "en.wikipedia.org (parse) Argentina\n",
      "Argentina (en) data\n",
      "{\n",
      "  infobox: <dict(79)> conventional_long_name, native_name, common_...\n",
      "  iwlinks: <list(19)> https://commons.wikimedia.org/wiki/Argentina...\n",
      "  pageid: 18951905\n",
      "  parsetree: <str(390014)> <root><template><title>Short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Argentina\n",
      "  wikibase: Q414\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q414\n",
      "  wikitext: <str(253603)> {{Short description|Country in South Ame...\n",
      "}\n",
      "en.wikipedia.org (parse) Armenia\n",
      "Armenia (en) data\n",
      "{\n",
      "  infobox: <dict(102)> conventional_long_name, common_name, native...\n",
      "  iwlinks: <list(14)> https://commons.wikimedia.org/wiki/%D5%80%D5...\n",
      "  pageid: 10918072\n",
      "  parsetree: <str(286989)> <root><template><title>short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Armenia\n",
      "  wikibase: Q399\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q399\n",
      "  wikitext: <str(230185)> {{short description|Country in West Asia...\n",
      "}\n",
      "en.wikipedia.org (parse) Australia\n",
      "Australia (en) data\n",
      "{\n",
      "  infobox: <dict(77)> conventional_long_name, common_name, image_f...\n",
      "  iwlinks: <list(11)> https://commons.wikimedia.org/wiki/Atlas_of_...\n",
      "  pageid: 4689264\n",
      "  parsetree: <str(335701)> <root><template><title>Short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Australia\n",
      "  wikibase: Q408\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q408\n",
      "  wikitext: <str(274275)> {{Short description|Country in Oceania}}...\n",
      "}\n",
      "en.wikipedia.org (parse) Austria\n",
      "Austria (en) data\n",
      "{\n",
      "  infobox: <dict(90)> conventional_long_name, common_name, native_...\n",
      "  iwlinks: <list(10)> https://commons.wikimedia.org/wiki/%C3%96ste...\n",
      "  pageid: 26964606\n",
      "  parsetree: <str(231128)> <root><template><title>Short descriptio...\n",
      "  requests: <list(1)> parse\n",
      "  title: Austria\n",
      "  wikibase: Q40\n",
      "  wikidata_url: https://www.wikidata.org/wiki/Q40\n",
      "  wikitext: <str(181823)> {{Short description|Country in Central E...\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'population_estimate': '{{IncreaseNeutral}} 41,128,771',\n",
       " 'population_estimate_year': '2023',\n",
       " 'GDP_PPP': '$81.007&nbsp;billion',\n",
       " 'GDP_PPP_year': '2020',\n",
       " 'GDP_PPP_rank': '',\n",
       " 'GDP_PPP_per_capita': '$2,459',\n",
       " 'GDP_PPP_per_capita_rank': '',\n",
       " 'country_name': 'Afghanistan'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list\n",
    "wiki_data = []\n",
    "# attributes of interest contained within the wiki infoboxes\n",
    "features = ['population_estimate', 'population_estimate_year', 'GDP_PPP', 'GDP_PPP_year', 'GDP_PPP_rank', 'GDP_PPP_per_capita',\n",
    "        'GDP_PPP_per_capita_rank']\n",
    "\n",
    "# fetching the data for all 10 countries\n",
    "for country in countries:    \n",
    "    page = wptools.page(country) # create a page object\n",
    "    try:\n",
    "        page.get_parse() # call the API and parse the data\n",
    "        if page.data['infobox'] != None:\n",
    "            # if infobox is present\n",
    "            infobox = page.data['infobox']\n",
    "            # get data for the interested features/attributes\n",
    "            data = { feature : infobox[feature] if feature in infobox else '' \n",
    "                         for feature in features }\n",
    "        else:\n",
    "            data = { feature : '' for feature in features }\n",
    "\n",
    "        data['country_name'] = country\n",
    "        wiki_data.append(data)\n",
    "\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "# checking the first entity of our list\n",
    "wiki_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441a270",
   "metadata": {
    "papermill": {
     "duration": 0.015237,
     "end_time": "2024-07-31T08:41:39.219609",
     "exception": false,
     "start_time": "2024-07-31T08:41:39.204372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "And last part, save it into a json file for later use. Next step offcourse wrangling and cleaning our dataset. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b795b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T08:41:39.246817Z",
     "iopub.status.busy": "2024-07-31T08:41:39.246409Z",
     "iopub.status.idle": "2024-07-31T08:41:39.252798Z",
     "shell.execute_reply": "2024-07-31T08:41:39.251710Z"
    },
    "papermill": {
     "duration": 0.023063,
     "end_time": "2024-07-31T08:41:39.255582",
     "exception": false,
     "start_time": "2024-07-31T08:41:39.232519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('infoboxes.json', 'w') as file:\n",
    "    json.dump(wiki_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90ba09",
   "metadata": {
    "papermill": {
     "duration": 0.014704,
     "end_time": "2024-07-31T08:41:39.283784",
     "exception": false,
     "start_time": "2024-07-31T08:41:39.269080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Legal use of web scraping\n",
    "\n",
    "There are many misinformations about web scraping. Many people believe it is illegal to use it but that only occurs when you try to scrape personal informations like a private message of a person. There are some rules when you are scraping data.\n",
    "\n",
    "# Scraping Rules\n",
    "\n",
    "1. You should check a website’s Terms and Conditions before you scrape it. Be careful to read the statements about legal use of data. Usually, the data you scrape should not be used for commercial purposes. Check the Website Terms of Service: Start by reading the terms of service, terms of use, or website’s “robots.txt” file (You can find it usually adding in the home page of the site the extention: /robots.txt). Many websites explicitly state whether web scraping is allowed or prohibited. Following these terms is essential for legal scraping.\n",
    "2. Do not request data from the website too aggressively with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "3. The layout of a website may change from time to time, so make sure to revisit the site and rewrite your code as needed\n",
    "\n",
    "Consult Legal Advice: When in doubt, make sure you consult with a legal counsel who specializes in technology and internet law. They can provide advice specific to your situation and jurisdiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841135c1",
   "metadata": {
    "papermill": {
     "duration": 0.013729,
     "end_time": "2024-07-31T08:41:39.312617",
     "exception": false,
     "start_time": "2024-07-31T08:41:39.298888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### References\n",
    "\n",
    "https://blog.gopenai.com/web-scraping-with-python-part-1-simple-static-website-84e0bddd5acd <br>\n",
    "https://blog.gopenai.com/web-scraping-with-python-part-2-dynamic-website-e0364a89e058 <br>\n",
    "https://saturncloud.io/blog/how-to-fix-the-pandas-unicodedecodeerror-utf8-codec-cant-decode-bytes-in-position-01-invalid-continuation-byte-error/ <br>\n",
    "https://monashdatafluency.github.io/python-web-scraping/section-3-API-based-scraping/"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5113769,
     "sourceId": 8556654,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 78.109251,
   "end_time": "2024-07-31T08:41:39.951273",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T08:40:21.842022",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
